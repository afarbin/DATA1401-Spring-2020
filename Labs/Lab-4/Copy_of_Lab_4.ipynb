{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.1"
    },
    "colab": {
      "name": "Copy of Lab-4.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoBj18wB_1fa",
        "colab_type": "text"
      },
      "source": [
        "## Lab 4\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github//afarbin/DATA1401-Spring-2020/blob/master/Labs/Lab-4/Lab-4.ipynb)\n",
        "\n",
        "In this lab we will become familiar with distributions, histograms, and functional programming. \n",
        "\n",
        "\n",
        "### Uniform Distribution\n",
        "Lets start with generating some fake random data. You can get a random number between 0 and 1 using the python random module as follow:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmrUVAv1_1ff",
        "colab_type": "code",
        "outputId": "058f7f18-c5ce-4f3b-fae6-b60a75b39d15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import random\n",
        "x=random.random()\n",
        "print(\"The Value of x is\", x)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Value of x is 0.3386614209151734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtxsuHTs_1fw",
        "colab_type": "text"
      },
      "source": [
        "Everytime you call random, you will get a new number.\n",
        "\n",
        "*Exercise 1:* Using random, write a function `generate_uniform(N, mymin, mymax)`, that returns a python list containing N random numbers between specified minimum and maximum value. Note that you may want to quickly work out on paper how to turn numbers between 0 and 1 to between other values. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9GzQB02_1fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Skeleton\n",
        "def generate_uniform(N,x_min,x_max):\n",
        "    out = []\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    while len(out) < N:\n",
        "      out.append(x_min + random.random() * (x_max - x_min))      \n",
        "    \n",
        "    ### END SOLUTION\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiWTH4-H_1f6",
        "colab_type": "code",
        "outputId": "0decf992-1467-425a-9f63-6ea6d5b5e9ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# Test your solution here\n",
        "data=generate_uniform(1000,-10,10)\n",
        "print(\"Data Type:\", type(data))\n",
        "print(\"Data Length:\", len(data))\n",
        "if len(data)>0: \n",
        "    print(\"Type of Data Contents:\", type(data[0]))\n",
        "    print(\"Data Minimum:\", min(data))\n",
        "    print(\"Data Maximum:\", max(data))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data Type: <class 'list'>\n",
            "Data Length: 1000\n",
            "Type of Data Contents: <class 'float'>\n",
            "Data Minimum: -9.993645208468072\n",
            "Data Maximum: 9.999142279088858\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOUqBefH_1gA",
        "colab_type": "text"
      },
      "source": [
        "*Exercise 2a:* \n",
        "Write a function that computes the mean of values in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sDXXVHB_1gE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Skeleton\n",
        "def mean(Data):\n",
        "    m=0.\n",
        "    \n",
        "    ### BEGIN SOLUTION\n",
        "    \n",
        "    m = sum(Data) / len(Data)\n",
        "    \n",
        "    ### END SOLUTION\n",
        "    \n",
        "    return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Z8u7_Hq_1gK",
        "colab_type": "code",
        "outputId": "f48293be-eb50-4d9c-83ea-b80f755f8a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test your solution here\n",
        "print(\"Mean of Data:\", mean(data))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean of Data: -0.43159352484900165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1CWdjfM_1gR",
        "colab_type": "text"
      },
      "source": [
        "*Exercise 2b:* \n",
        "Write a function that computes the variance of values in a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfiiJxZl_1gT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Skeleton\n",
        "def variance(Data):\n",
        "    m=0.\n",
        "    \n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    m = mean(Data)\n",
        "    variance = sum((x - m) ** 2 for x in Data) / len(Data)\n",
        "    \n",
        "    ### END SOLUTION\n",
        "    \n",
        "    return variance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbasE7ma_1gZ",
        "colab_type": "code",
        "outputId": "7fef8507-1e5f-440d-87c4-96c6190b5a1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test your solution here\n",
        "print(\"Variance of Data:\", variance(data))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variance of Data: 33.533919118720135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qtsjJNA_1ge",
        "colab_type": "text"
      },
      "source": [
        "## Histogramming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJsWb1o9_1gf",
        "colab_type": "text"
      },
      "source": [
        "*Exercise 3:* Write a function that bins the data so that you can create a histogram. An example of how to implement histogramming is the following logic:\n",
        "\n",
        "* User inputs a list of values `x` and optionally `n_bins` which defaults to 10.\n",
        "* If not supplied, find the minimum and maximum (`x_min`,`x_max`) of the values in x.\n",
        "* Determine the bin size (`bin_size`) by dividing the range of the function by the number of bins.\n",
        "* Create an empty list of zeros of size `n_bins`, call it `hist`.\n",
        "* Loop over the values in `x`\n",
        "    * Loop over the values in `hist` with index `i`:\n",
        "        * If x is between `x_min+i*bin_size` and `x_min+i*2*bin_size`, increment `hist[i].` \n",
        "        * For efficiency, try to use continue to goto the next bin and data point.\n",
        "* Return `hist` and the list corresponding of the bin edges (i.e. of `x_min+i*bin_size`).    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp85CdIF_1gh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Solution\n",
        "def histogram(x,n_bins=10,x_min=None,x_max=None):\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    if x_min == None:\n",
        "      x_min = min(x)\n",
        "    if x_max == None:\n",
        "      x_max = max(x)\n",
        "    \n",
        "    bin_size = (x_max - x_min) / n_bins\n",
        "\n",
        "    hist = [0] * n_bins\n",
        "    bin_edges = [x_min]\n",
        "    for i in range(1, n_bins + 1):\n",
        "      bin_edges.append(x_min + i * bin_size)\n",
        "    for value in x:\n",
        "      for i in range(n_bins):\n",
        "        if (x_min + (i * bin_size)) <= value <= (x_min + ((i + 1) * bin_size)):\n",
        "          hist[i] += 1\n",
        "          break\n",
        "    \n",
        "    ### END SOLUTION\n",
        "\n",
        "    return hist,bin_edges"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQg5EFMg_1gn",
        "colab_type": "code",
        "outputId": "e8539894-70b2-4a3c-d686-851a83c64c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Test your solution here\n",
        "h,b=histogram(data,100)\n",
        "print(len(b),h)"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 [11, 11, 11, 11, 12, 16, 11, 13, 7, 18, 11, 13, 10, 5, 6, 13, 7, 9, 11, 11, 5, 14, 10, 12, 11, 18, 7, 13, 10, 11, 11, 13, 5, 9, 8, 15, 8, 9, 8, 14, 16, 14, 8, 18, 8, 12, 4, 11, 10, 11, 9, 9, 11, 5, 8, 11, 9, 10, 10, 10, 5, 11, 15, 13, 11, 10, 8, 12, 6, 9, 5, 9, 8, 6, 8, 13, 10, 14, 10, 10, 6, 4, 7, 8, 10, 13, 9, 4, 10, 7, 9, 11, 4, 10, 11, 8, 16, 12, 6, 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miaZ7qfS_1gs",
        "colab_type": "text"
      },
      "source": [
        "*Exercise 4:* Write a function that uses the histogram function in the previous exercise to create a text-based \"graph\". For example the output could look like the following:\n",
        "```\n",
        "[  0,  1] : ######\n",
        "[  1,  2] : #####\n",
        "[  2,  3] : ######\n",
        "[  3,  4] : ####\n",
        "[  4,  5] : ####\n",
        "[  5,  6] : ######\n",
        "[  6,  7] : #####\n",
        "[  7,  8] : ######\n",
        "[  8,  9] : ####\n",
        "[  9, 10] : #####\n",
        "```\n",
        "\n",
        "Where each line corresponds to a bin and the number of `#`'s are proportional to the value of the data in the bin. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajxAao2B_1gt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Solution\n",
        "def draw_histogram(x,n_bins,x_min=None,x_max=None,character=\"#\",max_character_per_line=20):\n",
        "    ### BEGIN SOLUTION\n",
        "\n",
        "    bins = []\n",
        "\n",
        "    hist, bin_edges = histogram(x, n_bins, x_min, x_max)\n",
        "\n",
        "    max_hist = max(hist)\n",
        "\n",
        "    for i in range(len(bin_edges) - 1):\n",
        "      print(\"[\" + \"{:7.3f}\".format(bin_edges[i]) + \",\" + \"{:7.3f}\".format(bin_edges[i + 1]) + \"] : \" + (str(character) * int(hist[i] / max_hist * max_character_per_line)))\n",
        "    \n",
        "    ### END SOLUTION\n",
        "\n",
        "    return hist,bin_edges"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsQxIs9U_1gy",
        "colab_type": "code",
        "outputId": "f48acce2-3a92-4e7d-b855-7e741433df87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "# Test your solution here\n",
        "h,b=draw_histogram(data,20)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ -9.994, -8.994] : #################\n",
            "[ -8.994, -7.994] : ####################\n",
            "[ -7.994, -6.995] : #############\n",
            "[ -6.995, -5.995] : ###############\n",
            "[ -5.995, -4.995] : ################\n",
            "[ -4.995, -3.996] : ##################\n",
            "[ -3.996, -2.996] : ##############\n",
            "[ -2.996, -1.997] : ################\n",
            "[ -1.997, -0.997] : ###################\n",
            "[ -0.997,  0.003] : ##############\n",
            "[  0.003,  1.002] : ############\n",
            "[  1.002,  2.002] : ###############\n",
            "[  2.002,  3.002] : ################\n",
            "[  3.002,  4.001] : #############\n",
            "[  4.001,  5.001] : ###########\n",
            "[  5.001,  6.001] : #################\n",
            "[  6.001,  7.000] : ##########\n",
            "[  7.000,  8.000] : #############\n",
            "[  8.000,  9.000] : #############\n",
            "[  9.000,  9.999] : ################\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppoPnjV4_1g3",
        "colab_type": "text"
      },
      "source": [
        "## Functional Programming\n",
        "\n",
        "*Exercise 5:* Write a function the applies a booling function (that returns true/false) to every element in data, and return a list of indices of elements where the result was true. Use this function to find the indices of entries greater than 0.5. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTTvnZDl_1hK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def where(mylist,myfunc):\n",
        "    out= []\n",
        "    \n",
        "    ### BEGIN SOLUTION\n",
        "    for i in range(len(mylist)):\n",
        "      if myfunc(mylist[i]):\n",
        "        out.append(i)       \n",
        "    \n",
        "    ### END SOLUTION\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyXbNZK7_1hS",
        "colab_type": "code",
        "outputId": "b088491e-1fd0-461d-e7eb-de2985e7d13f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Test your solution here\n",
        "def myfunc(n):\n",
        "  return n > 0.5\n",
        "\n",
        "print(where(data, myfunc))"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 3, 4, 5, 7, 8, 10, 16, 18, 22, 24, 30, 32, 33, 37, 39, 42, 43, 45, 47, 48, 49, 50, 58, 61, 63, 66, 70, 74, 75, 77, 80, 81, 82, 83, 85, 89, 93, 96, 97, 99, 101, 103, 105, 106, 107, 109, 112, 113, 115, 118, 119, 120, 123, 124, 126, 128, 129, 134, 135, 138, 140, 141, 142, 144, 146, 147, 149, 151, 152, 153, 155, 156, 159, 161, 170, 172, 173, 175, 176, 178, 181, 182, 186, 189, 191, 192, 193, 194, 195, 198, 199, 203, 204, 205, 207, 208, 212, 216, 221, 222, 223, 225, 227, 228, 231, 232, 233, 234, 235, 240, 241, 243, 247, 249, 251, 252, 253, 254, 255, 256, 257, 261, 262, 267, 269, 271, 274, 278, 280, 281, 282, 284, 287, 288, 292, 295, 296, 298, 305, 306, 311, 313, 316, 317, 318, 319, 320, 323, 325, 326, 327, 331, 333, 334, 339, 342, 346, 349, 350, 356, 359, 361, 362, 364, 366, 367, 369, 370, 372, 373, 374, 378, 380, 381, 382, 389, 394, 395, 399, 400, 401, 403, 406, 409, 416, 419, 421, 422, 423, 424, 425, 426, 429, 431, 432, 434, 437, 438, 439, 442, 444, 450, 451, 452, 455, 456, 458, 460, 461, 468, 470, 472, 473, 478, 479, 480, 488, 489, 491, 493, 494, 496, 497, 498, 502, 503, 504, 507, 511, 512, 515, 516, 517, 519, 521, 523, 525, 526, 527, 531, 532, 533, 534, 540, 541, 543, 546, 547, 549, 551, 553, 556, 559, 561, 566, 567, 568, 569, 570, 574, 576, 578, 581, 584, 585, 587, 588, 589, 594, 598, 601, 603, 604, 605, 606, 607, 611, 613, 614, 617, 622, 625, 626, 627, 629, 634, 635, 636, 638, 639, 640, 642, 645, 646, 648, 652, 654, 655, 656, 658, 659, 661, 671, 674, 680, 682, 683, 686, 687, 688, 692, 695, 696, 699, 701, 702, 703, 705, 706, 709, 711, 717, 718, 722, 726, 727, 728, 730, 731, 732, 735, 738, 739, 742, 747, 749, 750, 752, 753, 755, 759, 761, 762, 764, 769, 770, 773, 774, 778, 782, 783, 784, 785, 790, 801, 802, 804, 808, 810, 813, 814, 815, 820, 822, 826, 827, 828, 835, 839, 841, 844, 847, 850, 854, 855, 857, 860, 861, 862, 863, 864, 866, 867, 868, 871, 876, 880, 881, 887, 889, 891, 892, 893, 897, 898, 900, 902, 903, 909, 911, 912, 915, 919, 920, 926, 930, 932, 933, 936, 938, 941, 943, 944, 946, 948, 951, 952, 956, 957, 958, 959, 961, 962, 964, 967, 968, 975, 976, 978, 979, 982, 983, 988, 990, 993, 997, 999]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt4S-KN0_1hZ",
        "colab_type": "text"
      },
      "source": [
        "*Exercise 6:* The inrange(mymin,mymax) function below returns a function that tests if it's input is between the specified values. Write corresponding functions that test:\n",
        "* Even\n",
        "* Odd\n",
        "* Greater than\n",
        "* Less than\n",
        "* Equal\n",
        "* Divisible by"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkchtWxy_1hb",
        "colab_type": "code",
        "outputId": "bc52f15f-2477-4d2b-f859-50ab6b3304d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def in_range(mymin,mymax):\n",
        "    def testrange(x):\n",
        "        return x<mymax and x>=mymin\n",
        "    return testrange\n",
        "\n",
        "# Examples:\n",
        "F1=in_range(0,10)\n",
        "F2=in_range(10,20)\n",
        "\n",
        "# Test of in_range\n",
        "print(F1(0), F1(1), F1(10), F1(15), F1(20))\n",
        "print(F2(0), F2(1), F2(10), F2(15), F2(20))\n",
        "\n",
        "print(\"Number of Entries passing F1:\", len(where(data,F1)))\n",
        "print(\"Number of Entries passing F2:\", len(where(data,F2)))"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True True False False False\n",
            "False False True True False\n",
            "Number of Entries passing F1: 461\n",
            "Number of Entries passing F2: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcReOq0v_1hf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### BEGIN SOLUTION\n",
        "\n",
        "def even():\n",
        "  def is_even(x):\n",
        "    return x % 2 == 0\n",
        "  return is_even\n",
        "\n",
        "def odd():\n",
        "  def is_odd(x):\n",
        "    return x % 2 == 1\n",
        "  return is_odd\n",
        "\n",
        "def greater_than(n):\n",
        "  def is_greater_than(x):\n",
        "    return x > n\n",
        "  return is_greater_than\n",
        "\n",
        "def less_than(n):\n",
        "  def is_less_than(x):\n",
        "    return x < n\n",
        "  return is_less_than\n",
        "\n",
        "def equal_to(n):\n",
        "  def is_equal_to(x):\n",
        "    return x == n\n",
        "  return is_equal_to\n",
        "\n",
        "def divisible_by(n):\n",
        "  def is_divisible_by(x):\n",
        "    return x % n == 0\n",
        "  return is_divisible_by\n",
        "    \n",
        "### END SOLUTION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AhyJZjf_1hj",
        "colab_type": "code",
        "outputId": "d2d12fa2-9ecb-4f72-fae8-955c52fed6bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Test your solution\n",
        "E = even()\n",
        "O = odd()\n",
        "G = greater_than(0)\n",
        "L = less_than(0)\n",
        "EQ = equal_to(data[20])\n",
        "D = divisible_by(data[50])\n",
        "\n",
        "print(E(2), O(2), G(2), L(2), EQ(2), D(2))\n",
        "print(E(-1), O(-1), G(-1), L(-1), EQ(-1), D(-1))\n",
        "\n",
        "print(\"Number of Entries passing E:\", len(where(data,E)))\n",
        "print(\"Number of Entries passing O:\", len(where(data,O)))\n",
        "print(\"Number of Entries passing G:\", len(where(data,G)))\n",
        "print(\"Number of Entries passing L:\", len(where(data,L)))\n",
        "print(\"Number of Entries passing EQ:\", len(where(data,EQ)))\n",
        "print(\"Number of Entries passing D:\", len(where(data,D)))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True False True False False False\n",
            "False True False True False False\n",
            "Number of Entries passing E: 0\n",
            "Number of Entries passing O: 0\n",
            "Number of Entries passing G: 461\n",
            "Number of Entries passing L: 539\n",
            "Number of Entries passing EQ: 1\n",
            "Number of Entries passing D: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEhLwDyH_1hq",
        "colab_type": "text"
      },
      "source": [
        "*Exercise 7:* Repeat the previous exercise using `lambda` and the built-in python functions sum and map instead of your solution above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlWCyUXL_1hr",
        "colab_type": "code",
        "outputId": "b4fc8f30-8ccd-4c30-8363-5cf121cfc1ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "### BEGIN SOLUTION\n",
        "\n",
        "print(\"Number of Entries passing E:\", sum(map(lambda x: x % 2 == 0,data)))\n",
        "print(\"Number of Entries passing O:\", sum(map(lambda x: x % 2 == 1, data)))\n",
        "print(\"Number of Entries passing G:\", sum(map(lambda x: x > 0, data)))\n",
        "print(\"Number of Entries passing L:\", sum(map(lambda x: x < 0, data)))\n",
        "print(\"Number of Entries passing EQ:\", sum(map(lambda x: x == data[20], data)))\n",
        "print(\"Number of Entries passing D:\", sum(map(lambda x: x % data[50] == 0, data)))\n",
        "### END SOLUTION"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Entries passing E: 0\n",
            "Number of Entries passing O: 0\n",
            "Number of Entries passing G: 461\n",
            "Number of Entries passing L: 539\n",
            "Number of Entries passing EQ: 1\n",
            "Number of Entries passing D: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IsTjLuQ_1hz",
        "colab_type": "text"
      },
      "source": [
        "## Monte Carlo\n",
        "\n",
        "*Exercise 7:* Write a \"generator\" function called `generate_function(func,x_min,x_max,N)`, that instead of generating a flat distribution, generates a distribution with functional form coded in `func`. Note that `func` will always be > 0.  \n",
        "\n",
        "Use the test function below and your histogramming functions above to demonstrate that your generator is working properly.\n",
        "\n",
        "Hint: A simple, but slow, solution is to a draw random number test_x within the specified range and another number p between the min and max of the function (which you will have to determine). If p<=function(test_x), then place test_x on the output. If not, repeat the process, drawing two new numbers. Repeat until you have the specified number of generated numbers, N. For this problem, it's OK to determine the min and max by numerically sampling the function.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL7k4NeJ_1h1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_function(func,x_min,x_max,N=1000):\n",
        "    out = list()\n",
        "    ### BEGIN SOLUTION\n",
        "    d = (x_max - x_min) / N\n",
        "    numbers = [x * d + x_min for x in range(N + 1)]\n",
        "    frequency = [func(n * d + x_min) for n in range(N + 1)]\n",
        "    #aux = [frequency[0]] + [0] * N\n",
        "    for i in range(1, N + 1):\n",
        "      frequency[i] = (frequency[i - 1] + frequency[i])\n",
        "    #print(*zip(numbers, frequency))\n",
        "    #print(numbers)\n",
        "    #print(frequency)\n",
        "    while len(out) < N:\n",
        "      num = random.random() * frequency[-1]\n",
        "      #print(num)\n",
        "      for i in range(len(frequency)):\n",
        "        if frequency[i] >= num:\n",
        "          out.append(numbers[i])\n",
        "          #print(frequency[i], num)\n",
        "          break\n",
        "    ### END SOLUTION\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOfuFLBX_1h6",
        "colab_type": "code",
        "outputId": "2a9dd381-1f7f-4ae0-f0f4-13b584dbd89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# A test function\n",
        "def test_func(x,a=1,b=1):\n",
        "    return abs(a*x+b)\n",
        "x_min = 0\n",
        "x_max = 10\n",
        "N = 1000\n",
        "n_bins = 20\n",
        "draw_histogram(generate_function(lambda x: -((x - 5)**2) + 5 ** 2, x_min, x_max, N), n_bins, x_min, x_max, \"#\", 50)\n",
        "draw_histogram(generate_function(test_func, x_min, x_max, N), n_bins, x_min, x_max, \"#\", 50)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0.000,  0.500] : ##\n",
            "[  0.500,  1.000] : #############\n",
            "[  1.000,  1.500] : ###################\n",
            "[  1.500,  2.000] : ##################\n",
            "[  2.000,  2.500] : ##########################\n",
            "[  2.500,  3.000] : #################################\n",
            "[  3.000,  3.500] : ########################################\n",
            "[  3.500,  4.000] : #########################################\n",
            "[  4.000,  4.500] : ###########################################\n",
            "[  4.500,  5.000] : ##################################################\n",
            "[  5.000,  5.500] : ###########################################\n",
            "[  5.500,  6.000] : #########################################\n",
            "[  6.000,  6.500] : ########################################\n",
            "[  6.500,  7.000] : ###################################\n",
            "[  7.000,  7.500] : #######################################\n",
            "[  7.500,  8.000] : #########################\n",
            "[  8.000,  8.500] : ########################\n",
            "[  8.500,  9.000] : ##############\n",
            "[  9.000,  9.500] : #################\n",
            "[  9.500, 10.000] : ###\n",
            "[  0.000,  0.500] : ######\n",
            "[  0.500,  1.000] : ###########\n",
            "[  1.000,  1.500] : ############\n",
            "[  1.500,  2.000] : #########\n",
            "[  2.000,  2.500] : #############\n",
            "[  2.500,  3.000] : ################\n",
            "[  3.000,  3.500] : #######################\n",
            "[  3.500,  4.000] : ##########################\n",
            "[  4.000,  4.500] : ##########################\n",
            "[  4.500,  5.000] : ################################\n",
            "[  5.000,  5.500] : ###########################\n",
            "[  5.500,  6.000] : ################################\n",
            "[  6.000,  6.500] : ########################################\n",
            "[  6.500,  7.000] : ###########################################\n",
            "[  7.000,  7.500] : ##################################\n",
            "[  7.500,  8.000] : ###################################\n",
            "[  8.000,  8.500] : ############################################\n",
            "[  8.500,  9.000] : ###############################################\n",
            "[  9.000,  9.500] : ##############################################\n",
            "[  9.500, 10.000] : ##################################################\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([12,\n",
              "  19,\n",
              "  21,\n",
              "  17,\n",
              "  23,\n",
              "  29,\n",
              "  40,\n",
              "  45,\n",
              "  45,\n",
              "  56,\n",
              "  48,\n",
              "  56,\n",
              "  70,\n",
              "  74,\n",
              "  59,\n",
              "  61,\n",
              "  77,\n",
              "  82,\n",
              "  80,\n",
              "  86],\n",
              " [0,\n",
              "  0.5,\n",
              "  1.0,\n",
              "  1.5,\n",
              "  2.0,\n",
              "  2.5,\n",
              "  3.0,\n",
              "  3.5,\n",
              "  4.0,\n",
              "  4.5,\n",
              "  5.0,\n",
              "  5.5,\n",
              "  6.0,\n",
              "  6.5,\n",
              "  7.0,\n",
              "  7.5,\n",
              "  8.0,\n",
              "  8.5,\n",
              "  9.0,\n",
              "  9.5,\n",
              "  10.0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEdnKUPz_1h-",
        "colab_type": "text"
      },
      "source": [
        "*Exercise 8:* Use your function to generate 1000 numbers that are normal distributed, using the `gaussian` function below. Confirm the mean and variance of the data is close to the mean and variance you specify when building the Gaussian. Histogram the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnZFkATK_1h_",
        "colab_type": "code",
        "outputId": "befea955-38c3-416e-d872-97c4511b2a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        }
      },
      "source": [
        "import math\n",
        "\n",
        "def gaussian(mean, sigma):\n",
        "    def f(x):\n",
        "        return math.exp(-((x-mean)**2)/(2*sigma**2))/math.sqrt(math.pi*sigma)\n",
        "    return f\n",
        "\n",
        "# Example Instantiation\n",
        "g1=gaussian(0,1)\n",
        "g2=gaussian(10,3)\n",
        "\n",
        "g1_data = generate_function(g1, -4, 4, 1000)\n",
        "g2_data = generate_function(g2, 0, 20, 1000)\n",
        "print(g1_data)\n",
        "print(g2_data)\n",
        "draw_histogram(g1_data, 20)\n",
        "print(\"g1 mean = \" + str(mean(g1_data)))\n",
        "print(\"g1 variance = \" + str(variance(g1_data)))\n",
        "draw_histogram(g2_data, 20)\n",
        "print(\"g2 mean = \" + str(mean(g2_data)))\n",
        "print(\"g2 variance = \" + str(variance(g2_data)))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.6879999999999997, 1.3200000000000003, -1.424, -1.0, -0.7199999999999998, -0.3839999999999999, 0.8479999999999999, -1.1680000000000001, -0.43199999999999994, 0.41600000000000037, -0.3919999999999999, 0.13600000000000012, 0.48800000000000043, 0.28000000000000025, 0.16800000000000015, 2.4000000000000004, -0.472, -0.5920000000000001, -0.3679999999999999, 0.3440000000000003, 0.3360000000000003, 1.4960000000000004, -1.56, 1.096, -0.43199999999999994, -0.008000000000000007, -0.496, 1.1600000000000001, -1.592, 0.016000000000000014, 0.8959999999999999, 0.8639999999999999, 0.26400000000000023, 0.2240000000000002, -0.6959999999999997, -0.008000000000000007, -0.7919999999999998, 1.4160000000000004, -1.528, 0.41600000000000037, 0.6319999999999997, -2.7119999999999997, -0.6320000000000001, 2.6480000000000006, 1.0, -1.072, -0.7199999999999998, -0.43999999999999995, -0.6959999999999997, 0.3520000000000003, -1.3359999999999999, -0.6959999999999997, 0.8559999999999999, -2.112, 0.40800000000000036, -1.96, 1.12, 0.5200000000000005, 1.96, -0.08800000000000008, 0.4720000000000004, 0.15200000000000014, 1.1440000000000001, -0.31199999999999983, 1.2400000000000002, -0.552, -0.2639999999999998, -0.21599999999999975, -0.7759999999999998, -0.45599999999999996, -0.2879999999999998, -1.048, 1.032, 0.09600000000000009, 1.1920000000000002, 0.3520000000000003, -0.4079999999999999, -0.6320000000000001, -0.3039999999999998, -1.1440000000000001, 1.3920000000000003, -0.10400000000000009, -1.472, 0.5360000000000005, 0.4240000000000004, -0.3599999999999999, 0.7839999999999998, 0.6959999999999997, 1.5920000000000005, -0.05600000000000005, -0.48, 0.5440000000000005, -0.2559999999999998, 0.30400000000000027, 1.4240000000000004, -0.968, -0.7999999999999998, 2.128, 0.5680000000000005, -2.416, 0.3200000000000003, 0.08000000000000007, 0.5760000000000005, 0.30400000000000027, -0.3759999999999999, -1.616, -1.2719999999999998, -1.1999999999999997, -0.7279999999999998, 1.3920000000000003, 0.14400000000000013, 0.28800000000000026, -0.3679999999999999, 0.5200000000000005, -0.7599999999999998, -0.7279999999999998, -1.968, -0.7439999999999998, -1.944, 0.17600000000000016, -0.18399999999999972, 0.2240000000000002, -0.976, -0.3679999999999999, 0.03200000000000003, 0.26400000000000023, -0.19199999999999973, 1.7519999999999998, -1.1680000000000001, 0.5600000000000005, 1.4000000000000004, -0.31199999999999983, -0.16000000000000014, 0.16000000000000014, 1.8399999999999999, 0.6159999999999997, 0.02400000000000002, 0.2320000000000002, -1.2319999999999998, 0.6719999999999997, 0.7119999999999997, 0.29600000000000026, 1.2240000000000002, 0.5920000000000005, -0.2719999999999998, 0.16000000000000014, -0.512, -0.8319999999999999, -0.536, 1.4240000000000004, -1.1840000000000002, -0.08000000000000007, 0.14400000000000013, 1.2320000000000002, 0.26400000000000023, 0.8159999999999998, -0.2639999999999998, 0.8159999999999998, -1.592, -0.6879999999999997, 0.2320000000000002, 0.944, -0.528, 1.12, 0.5200000000000005, -0.19199999999999973, -0.14400000000000013, 0.008000000000000007, -1.6400000000000001, -0.3599999999999999, 0.10400000000000009, -0.23199999999999976, 0.2400000000000002, 0.1120000000000001, 1.1600000000000001, 0.4240000000000004, -0.56, -1.1840000000000002, -1.064, -1.6560000000000001, 0.7359999999999998, 0.6799999999999997, 0.8239999999999998, 0.6080000000000005, 0.03200000000000003, -0.22399999999999975, 0.7759999999999998, -2.528, -0.5920000000000001, -0.23999999999999977, 2.008, 0.41600000000000037, -1.032, -0.06400000000000006, 0.6799999999999997, -0.6959999999999997, 1.3040000000000003, -0.31999999999999984, 1.024, -0.040000000000000036, -1.1360000000000001, 0.48800000000000043, 1.032, 0.7839999999999998, -0.3599999999999999, -0.952, -0.1120000000000001, -0.488, 0.24800000000000022, -0.8879999999999999, -2.016, -1.2719999999999998, -2.168, 1.952, -0.6799999999999997, 1.088, -1.2879999999999998, -0.7679999999999998, -0.7119999999999997, -0.2879999999999998, 0.5600000000000005, 1.4880000000000004, 1.8719999999999999, -1.8479999999999999, -1.472, 0.15200000000000014, -0.6480000000000001, 1.024, -0.33599999999999985, -0.16000000000000014, 0.17600000000000016, 0.7439999999999998, 0.1200000000000001, -0.96, 0.10400000000000009, -0.9039999999999999, -0.2639999999999998, -0.10400000000000009, 0.1120000000000001, -0.8639999999999999, 1.088, -0.1679999999999997, -1.7199999999999998, 1.7439999999999998, -0.1280000000000001, 1.5200000000000005, -0.7119999999999997, 2.152, 0.18400000000000016, -0.45599999999999996, -1.0, 0.16000000000000014, -0.23999999999999977, -0.20799999999999974, -0.008000000000000007, 0.9199999999999999, 0.5200000000000005, 2.2800000000000002, 0.4640000000000004, 0.24800000000000022, -0.8479999999999999, -0.24799999999999978, -2.0, 0.40800000000000036, 1.056, -0.2799999999999998, 0.7839999999999998, 0.18400000000000016, -0.7759999999999998, -0.31999999999999984, 0.5360000000000005, -0.7679999999999998, -0.8639999999999999, 0.14400000000000013, 0.05600000000000005, 0.3520000000000003, 0.5280000000000005, 1.4320000000000004, 2.184, 1.992, 0.3360000000000003, 1.8399999999999999, 0.6879999999999997, 1.2880000000000003, -0.8239999999999998, -0.6240000000000001, 1.912, -1.536, 0.37600000000000033, 0.2560000000000002, -0.7119999999999997, 0.9039999999999999, -1.6560000000000001, 0.7119999999999997, 1.912, -0.45599999999999996, 0.7039999999999997, -0.96, 0.8479999999999999, 0.8159999999999998, -0.3999999999999999, 0.3680000000000003, 0.6000000000000005, 0.6559999999999997, 0.7039999999999997, -0.44799999999999995, -0.7039999999999997, -0.19199999999999973, 0.6719999999999997, 0.7359999999999998, 0.37600000000000033, -1.056, 0.2320000000000002, 0.2560000000000002, -0.2959999999999998, -0.5920000000000001, -0.7679999999999998, -1.2239999999999998, -1.008, -0.14400000000000013, -0.96, 0.992, 1.4720000000000004, 0.16000000000000014, 0.26400000000000023, 0.39200000000000035, -0.6480000000000001, 0.15200000000000014, -1.3679999999999999, -0.31999999999999984, -0.5840000000000001, 0.9279999999999999, 1.2880000000000003, -0.8799999999999999, -2.576, -0.24799999999999978, -1.576, 1.112, -0.06400000000000006, -1.1760000000000002, -0.3999999999999999, -1.0, 0.8799999999999999, 0.04800000000000004, -0.21599999999999975, 0.49600000000000044, 1.1680000000000001, -0.2879999999999998, -0.8799999999999999, 0.6719999999999997, -0.528, -1.4, 0.7439999999999998, -2.216, -0.09600000000000009, 0.5840000000000005, 0.8079999999999998, 0.6399999999999997, -1.536, 0.952, -0.1679999999999997, -0.6080000000000001, 0.7919999999999998, -0.2799999999999998, 1.1440000000000001, -0.504, -0.42399999999999993, -1.2079999999999997, 1.6000000000000005, -1.912, -0.7919999999999998, -0.15200000000000014, -1.624, -1.608, 0.9279999999999999, -0.15200000000000014, -0.24799999999999978, -0.13600000000000012, -1.584, 1.024, -0.35199999999999987, 0.38400000000000034, -1.7119999999999997, 0.8559999999999999, -0.8639999999999999, -0.34399999999999986, 0.5040000000000004, 0.3680000000000003, -3.216, 0.18400000000000016, 0.5920000000000005, -0.05600000000000005, -1.088, 0.5840000000000005, -0.56, 1.888, -0.472, -0.2879999999999998, -1.536, -2.832, -0.1759999999999997, -0.968, -0.8079999999999998, -0.3039999999999998, -0.31199999999999983, 0.04800000000000004, -2.168, 0.016000000000000014, 1.5040000000000004, 0.1120000000000001, -1.3199999999999998, -0.22399999999999975, -0.6719999999999997, -1.2559999999999998, -0.7279999999999998, 0.39200000000000035, -1.056, -0.21599999999999975, -1.024, -0.6160000000000001, 1.2880000000000003, 0.08800000000000008, -1.8159999999999998, 0.15200000000000014, 0.016000000000000014, 0.2240000000000002, -1.376, 0.96, 1.4960000000000004, 0.8879999999999999, 0.6080000000000005, 0.5360000000000005, 0.8079999999999998, -2.376, 0.8079999999999998, 1.2000000000000002, -2.888, -0.5920000000000001, -0.544, 0.6559999999999997, -1.0, -1.512, -0.19999999999999973, -0.3679999999999999, 2.216, 2.5440000000000005, -0.6240000000000001, -0.5920000000000001, -0.472, -0.16000000000000014, 0.7599999999999998, -0.3839999999999999, -0.3679999999999999, -1.2479999999999998, -1.2479999999999998, -0.2639999999999998, -0.42399999999999993, -1.1680000000000001, 1.064, -1.088, -3.2640000000000002, 1.032, -1.8719999999999999, 1.5040000000000004, -0.35199999999999987, 0.1280000000000001, -0.20799999999999974, -1.912, 1.088, 0.05600000000000005, 0.13600000000000012, 2.3600000000000003, 0.13600000000000012, 0.28000000000000025, -0.34399999999999986, 0.07200000000000006, -0.24799999999999978, 1.6959999999999997, 0.3440000000000003, -0.3839999999999999, 0.4800000000000004, -0.02400000000000002, 0.040000000000000036, -0.6240000000000001, 0.1200000000000001, -0.33599999999999985, 0.6639999999999997, -0.1679999999999997, 0.5360000000000005, -0.8879999999999999, 0.28800000000000026, 0.8159999999999998, 1.12, -0.8079999999999998, 2.152, -0.23999999999999977, -1.096, 0.8479999999999999, 0.7439999999999998, 0.39200000000000035, -0.15200000000000014, 0.2160000000000002, 0.4640000000000004, -0.9039999999999999, 0.976, -1.1440000000000001, -0.472, -0.536, -1.12, -0.552, 0.02400000000000002, 0.06400000000000006, -1.04, -0.04800000000000004, -1.4, -1.376, -0.8159999999999998, 1.008, 1.3280000000000003, 0.08000000000000007, -0.952, -1.1280000000000001, -1.1360000000000001, 0.30400000000000027, 1.888, -0.2639999999999998, 0.10400000000000009, 1.7199999999999998, -0.20799999999999974, -1.032, -0.7039999999999997, -0.7119999999999997, -0.6480000000000001, -0.5680000000000001, 0.29600000000000026, -0.2639999999999998, -1.2559999999999998, -0.7519999999999998, -0.23999999999999977, 0.7999999999999998, -0.9119999999999999, -0.4159999999999999, -1.416, -0.7359999999999998, 0.9359999999999999, 1.6160000000000005, 0.6559999999999997, 0.9359999999999999, -0.7999999999999998, -0.7279999999999998, 0.09600000000000009, 0.6559999999999997, -0.5760000000000001, -0.6640000000000001, 1.8159999999999998, -0.2559999999999998, 0.6799999999999997, -0.3919999999999999, -1.576, 1.2400000000000002, 0.20800000000000018, -0.6080000000000001, 0.7919999999999998, 0.10400000000000009, -1.048, -0.6160000000000001, -0.016000000000000014, 0.40000000000000036, -0.24799999999999978, -0.040000000000000036, 0.5360000000000005, -0.984, 0.27200000000000024, -0.536, 0.7759999999999998, 0.2560000000000002, -0.8239999999999998, 3.6879999999999997, -0.984, -1.392, 0.19200000000000017, 0.7679999999999998, -1.104, 0.29600000000000026, -0.22399999999999975, -0.7359999999999998, 2.048, 0.4400000000000004, 0.24800000000000022, 0.5200000000000005, -3.432, -0.33599999999999985, 2.008, -0.18399999999999972, -0.7119999999999997, -0.7199999999999998, 1.2800000000000002, -0.48, -1.3599999999999999, -1.92, 0.20000000000000018, 1.1680000000000001, 0.20000000000000018, -0.008000000000000007, -0.2639999999999998, -0.20799999999999974, -0.504, -0.016000000000000014, -0.3599999999999999, -0.952, -0.02400000000000002, 0.26400000000000023, 0.6639999999999997, -0.3919999999999999, 0.07200000000000006, -0.7039999999999997, 1.4720000000000004, -0.7119999999999997, 0.2240000000000002, 0.24800000000000022, -0.488, -0.6799999999999997, 0.4640000000000004, -1.1680000000000001, 0.15200000000000014, 0.8479999999999999, -0.5680000000000001, 3.224, 0.16000000000000014, -0.7599999999999998, -0.42399999999999993, 2.208, -0.3759999999999999, -0.8079999999999998, -1.7679999999999998, -1.496, 1.5360000000000005, -1.912, 0.08800000000000008, -0.952, -0.984, 0.8239999999999998, -0.016000000000000014, -0.6640000000000001, 0.6719999999999997, 0.9039999999999999, 0.8559999999999999, 1.2880000000000003, -0.6879999999999997, 0.7199999999999998, -1.2399999999999998, -0.2879999999999998, -0.5920000000000001, 2.144, -0.44799999999999995, 0.8239999999999998, -1.016, 2.224, -0.3759999999999999, -0.03200000000000003, -0.2639999999999998, -0.8559999999999999, -1.096, 1.7599999999999998, -0.9199999999999999, 1.04, -0.22399999999999975, -0.6480000000000001, 0.15200000000000014, -0.32799999999999985, -1.968, -1.528, 1.7199999999999998, -1.448, 2.3360000000000003, 0.5120000000000005, -1.7039999999999997, 1.032, 0.7039999999999997, 0.7359999999999998, 0.5600000000000005, -0.8879999999999999, -1.608, -0.6879999999999997, -1.1280000000000001, 1.3520000000000003, 0.20000000000000018, 0.2560000000000002, -0.6640000000000001, 0.02400000000000002, 2.7359999999999998, -1.12, -1.376, -0.6400000000000001, 2.16, 0.37600000000000033, -0.504, -0.3599999999999999, -1.904, -0.34399999999999986, -0.992, -1.424, -1.1919999999999997, -0.22399999999999975, 0.9359999999999999, 0.37600000000000033, -0.8719999999999999, -0.13600000000000012, -1.6959999999999997, 0.17600000000000016, -0.6640000000000001, 1.3120000000000003, -0.3919999999999999, 1.5280000000000005, 1.2000000000000002, 0.09600000000000009, -0.09600000000000009, -1.6400000000000001, 0.6239999999999997, 1.1600000000000001, -0.24799999999999978, 1.2640000000000002, 0.5840000000000005, -0.48, -1.072, 1.008, -1.1600000000000001, 2.3920000000000003, 0.29600000000000026, 0.3440000000000003, 0.4320000000000004, 0.1280000000000001, -0.552, 1.7679999999999998, -0.7599999999999998, -0.3599999999999999, -0.31999999999999984, 0.17600000000000016, -0.3839999999999999, -0.32799999999999985, 0.7679999999999998, 0.6000000000000005, -1.064, -0.2719999999999998, 0.39200000000000035, -0.6719999999999997, 0.09600000000000009, 0.6000000000000005, 0.41600000000000037, 0.6239999999999997, -1.8159999999999998, -0.6400000000000001, 1.904, -0.22399999999999975, 0.7039999999999997, -0.4159999999999999, -1.52, -0.31199999999999983, 0.3200000000000003, 1.6799999999999997, 0.6239999999999997, 1.4240000000000004, -0.6400000000000001, -0.44799999999999995, 0.40000000000000036, 0.09600000000000009, -0.6000000000000001, 1.2800000000000002, -0.7199999999999998, -0.6879999999999997, 1.4240000000000004, -0.31999999999999984, 1.6319999999999997, 0.38400000000000034, 0.40000000000000036, -0.08000000000000007, 1.976, 0.6479999999999997, 0.5280000000000005, -1.3439999999999999, -1.096, -0.23199999999999976, 3.192, -0.7759999999999998, 0.24800000000000022, -0.16000000000000014, 0.4400000000000004, -1.952, 0.5600000000000005, -0.44799999999999995, 1.3200000000000003, -0.10400000000000009, 0.7919999999999998, 1.3520000000000003, -1.072, -0.7199999999999998, 0.6799999999999997, -1.2639999999999998, -1.6, 0.3680000000000003, 0.19200000000000017, 0.952, -1.7279999999999998, -0.8319999999999999, -0.15200000000000014, 0.7679999999999998, 0.5120000000000005, -0.23999999999999977, 0.39200000000000035, 0.7039999999999997, 0.9039999999999999, 2.088, 0.944, 1.5600000000000005, 0.6239999999999997, 0.2160000000000002, -0.8879999999999999, -0.5680000000000001, 2.2560000000000002, -0.1679999999999997, 0.6879999999999997, -1.2319999999999998, 2.048, 1.2720000000000002, 1.008, -0.8319999999999999, -0.6799999999999997, -1.584, 0.08800000000000008, -1.112, -2.0, 0.30400000000000027, 2.08, 1.088, -0.3999999999999999, 0.27200000000000024, 0.5680000000000005, -0.6400000000000001, 0.41600000000000037, -0.21599999999999975, 0.4240000000000004, -0.7359999999999998, -1.6880000000000002, 0.5680000000000005, -0.08800000000000008, -1.544, 1.2560000000000002, 1.8159999999999998, -1.1999999999999997, 0.944, 0.6559999999999997, -0.7359999999999998, 0.7199999999999998, 0.8799999999999999, -0.42399999999999993, -0.22399999999999975, 0.6959999999999997, -0.23999999999999977, -0.8719999999999999, 1.3760000000000003, 1.4640000000000004, 1.3360000000000003, 0.3120000000000003, 0.20000000000000018, -3.248, 0.5760000000000005, 1.912, 0.4480000000000004, 0.05600000000000005, -0.952, 0.3600000000000003, -1.6880000000000002, -0.6719999999999997, 0.14400000000000013, 0.6080000000000005, -0.07200000000000006, 0.9039999999999999, 1.7679999999999998, 0.07200000000000006, 0.2320000000000002, -0.8879999999999999, -0.06400000000000006, -1.112, -0.3919999999999999, -1.936, -0.02400000000000002, -0.18399999999999972, -1.072, 0.3280000000000003, -0.7039999999999997, -0.16000000000000014, -0.2959999999999998, -0.24799999999999978, 2.7359999999999998, 1.2480000000000002, 0.4240000000000004, 0.6559999999999997, -0.992, -0.7359999999999998, -2.2800000000000002, -0.35199999999999987, -0.48, 0.07200000000000006, -0.4159999999999999, -0.10400000000000009, 1.0, 1.6000000000000005, 0.952, -0.536, -1.52, -0.6240000000000001, -0.32799999999999985, 2.216, 1.5440000000000005, 0.49600000000000044, 0.984, -1.944, -1.1280000000000001, 1.2640000000000002, -1.4, -1.48, -1.8559999999999999, -0.46399999999999997, 0.1120000000000001, 0.3680000000000003, 1.5440000000000005, 0.06400000000000006, 2.192, -1.064, -2.144, 0.9039999999999999, -0.9199999999999999, -0.43199999999999994, -0.3599999999999999, -1.472, 1.7519999999999998, -0.6640000000000001, -1.8639999999999999, -0.984, 1.7119999999999997, -2.072, -0.05600000000000005, -0.08800000000000008, 0.8719999999999999, 0.49600000000000044, 0.976, 0.05600000000000005, 0.02400000000000002, 0.28800000000000026, -0.9039999999999999, -1.616, 0.2240000000000002, 0.8719999999999999, 0.2320000000000002, -0.07200000000000006, 0.5760000000000005, 2.04, 1.4000000000000004, 1.4320000000000004, 1.024, -0.6000000000000001, 0.4800000000000004, 1.2640000000000002, -0.512, -1.1600000000000001, -0.43199999999999994, -1.2559999999999998, 0.5920000000000005, -1.6560000000000001, 0.8719999999999999, 0.5440000000000005, -1.584, -0.952, 1.3360000000000003, -0.1759999999999997, -0.528, -1.08, 0.5920000000000005, -1.456, -1.424, 0.19200000000000017, 1.2800000000000002, 1.3200000000000003, 0.30400000000000027, -0.43999999999999995, -0.496, -0.48, -0.944, -0.02400000000000002, -0.8879999999999999, -1.384, 1.2800000000000002, 1.04, -0.984, 0.8239999999999998, 0.5680000000000005, -0.22399999999999975, -0.2639999999999998, 1.0, -0.5760000000000001]\n",
            "[8.9, 7.72, 6.34, 13.56, 9.36, 8.2, 7.08, 7.72, 9.120000000000001, 10.98, 10.9, 5.12, 8.58, 14.16, 16.0, 10.44, 7.46, 9.3, 7.04, 10.700000000000001, 8.4, 8.1, 9.66, 9.56, 10.9, 5.16, 11.700000000000001, 12.38, 9.26, 7.96, 6.8, 8.18, 6.48, 8.34, 10.92, 13.84, 11.200000000000001, 13.36, 11.4, 7.22, 11.56, 9.040000000000001, 17.16, 7.18, 3.3200000000000003, 6.88, 10.0, 9.56, 12.82, 10.92, 11.72, 10.08, 5.38, 7.26, 8.36, 5.16, 12.280000000000001, 12.620000000000001, 8.32, 16.38, 9.74, 11.52, 14.14, 14.76, 7.4, 7.5600000000000005, 9.700000000000001, 13.66, 14.120000000000001, 13.16, 10.06, 10.28, 10.92, 8.36, 9.0, 12.82, 12.92, 8.92, 12.44, 9.540000000000001, 5.42, 7.72, 5.7, 16.5, 14.66, 12.780000000000001, 12.6, 11.02, 9.96, 12.3, 11.66, 3.8200000000000003, 10.540000000000001, 14.9, 9.72, 11.4, 10.56, 11.46, 6.5600000000000005, 8.26, 14.66, 12.620000000000001, 9.42, 10.8, 12.08, 6.3, 6.44, 12.66, 9.26, 10.56, 5.68, 4.0200000000000005, 13.780000000000001, 12.8, 16.18, 2.82, 17.68, 7.44, 9.96, 6.9, 4.36, 9.82, 8.18, 11.040000000000001, 8.4, 7.76, 3.22, 8.22, 8.4, 8.94, 11.56, 12.8, 8.9, 7.9, 11.36, 11.38, 7.92, 13.98, 6.76, 7.72, 8.66, 9.98, 14.540000000000001, 8.8, 12.4, 6.44, 10.6, 2.7800000000000002, 6.32, 15.64, 10.620000000000001, 8.88, 16.18, 13.44, 9.48, 10.52, 7.74, 8.040000000000001, 12.82, 16.02, 8.32, 12.56, 14.02, 11.200000000000001, 9.36, 6.34, 7.8, 8.98, 7.78, 11.9, 11.0, 8.2, 4.6000000000000005, 13.52, 12.120000000000001, 7.92, 7.78, 7.46, 8.94, 12.96, 9.52, 13.280000000000001, 8.2, 16.7, 11.9, 6.8, 9.96, 4.6000000000000005, 11.76, 8.38, 14.620000000000001, 10.48, 12.18, 11.08, 4.94, 11.96, 11.76, 9.1, 10.6, 12.38, 12.9, 12.22, 6.72, 3.88, 6.48, 9.700000000000001, 8.82, 13.38, 12.86, 12.82, 13.26, 10.84, 6.62, 13.36, 14.200000000000001, 12.34, 8.16, 10.72, 8.34, 5.66, 7.4, 14.4, 8.5, 10.86, 11.96, 9.88, 11.48, 7.9, 6.42, 14.26, 8.5, 7.42, 7.32, 10.94, 5.0200000000000005, 10.6, 10.18, 8.96, 12.36, 14.08, 10.48, 10.98, 5.86, 14.02, 8.32, 9.040000000000001, 8.700000000000001, 10.18, 10.16, 6.2, 14.68, 7.44, 13.4, 9.18, 6.72, 8.1, 3.36, 12.44, 8.24, 6.46, 6.98, 13.06, 9.46, 8.46, 4.62, 8.540000000000001, 7.42, 7.44, 12.0, 12.18, 14.44, 12.88, 4.48, 13.08, 9.76, 7.18, 11.36, 13.66, 4.42, 7.4, 10.24, 14.48, 10.200000000000001, 7.16, 10.5, 12.56, 10.02, 7.16, 12.44, 10.28, 10.3, 15.9, 8.14, 10.56, 4.62, 9.64, 8.22, 12.14, 11.700000000000001, 13.32, 9.34, 6.24, 10.040000000000001, 11.700000000000001, 12.38, 15.200000000000001, 11.86, 8.22, 10.76, 10.28, 10.44, 6.6000000000000005, 10.96, 12.040000000000001, 8.1, 10.86, 10.5, 7.98, 8.44, 11.02, 10.68, 14.64, 5.76, 10.72, 14.120000000000001, 10.14, 11.1, 9.38, 10.8, 12.9, 6.36, 7.96, 10.82, 8.700000000000001, 10.24, 10.22, 8.72, 10.88, 10.92, 14.24, 10.1, 9.78, 8.2, 5.98, 8.74, 13.36, 8.26, 10.16, 18.82, 7.140000000000001, 7.54, 11.66, 8.46, 8.88, 4.44, 10.26, 12.6, 10.84, 10.3, 13.200000000000001, 9.68, 8.94, 7.54, 9.74, 9.26, 9.16, 9.96, 16.8, 11.46, 10.96, 8.620000000000001, 9.48, 9.18, 8.82, 11.34, 8.84, 5.38, 14.52, 12.620000000000001, 12.72, 11.28, 7.8, 5.66, 9.200000000000001, 11.4, 12.120000000000001, 11.0, 12.18, 9.6, 7.28, 8.72, 11.16, 9.56, 13.4, 6.640000000000001, 10.52, 9.42, 8.08, 10.46, 4.54, 13.5, 6.92, 9.94, 10.6, 12.3, 5.18, 9.9, 11.44, 9.9, 8.66, 12.120000000000001, 12.76, 10.3, 8.6, 8.42, 7.86, 7.72, 15.6, 6.640000000000001, 7.88, 10.58, 11.4, 8.52, 12.32, 8.02, 13.68, 11.84, 7.34, 9.48, 11.64, 7.8, 11.4, 10.32, 7.32, 11.06, 9.96, 6.42, 10.1, 8.620000000000001, 13.86, 12.6, 9.540000000000001, 8.120000000000001, 11.32, 8.96, 9.42, 12.44, 13.36, 13.08, 9.6, 11.02, 12.26, 9.44, 9.86, 6.28, 10.72, 10.84, 9.44, 10.9, 13.24, 10.84, 9.78, 4.92, 10.56, 5.58, 7.68, 12.280000000000001, 15.700000000000001, 9.28, 9.18, 14.98, 10.18, 10.86, 6.9, 13.74, 8.5, 12.040000000000001, 8.36, 7.88, 10.84, 11.52, 12.92, 18.42, 13.780000000000001, 13.24, 13.56, 11.16, 9.78, 9.94, 9.84, 12.42, 8.8, 7.8, 7.76, 10.700000000000001, 8.48, 12.34, 12.32, 5.74, 8.86, 8.9, 11.64, 8.74, 12.06, 7.84, 12.56, 11.02, 12.280000000000001, 9.9, 6.32, 7.86, 13.4, 9.44, 10.78, 8.08, 5.42, 10.06, 10.64, 12.22, 12.84, 8.74, 9.84, 9.4, 8.94, 10.06, 7.34, 7.9, 6.98, 13.620000000000001, 16.44, 10.040000000000001, 6.62, 12.18, 6.640000000000001, 6.82, 5.4, 12.22, 8.540000000000001, 9.22, 10.48, 9.92, 15.540000000000001, 9.24, 12.68, 3.04, 11.78, 8.620000000000001, 9.68, 9.8, 9.68, 10.24, 7.12, 9.18, 10.88, 13.96, 13.44, 6.640000000000001, 6.68, 13.0, 15.26, 15.6, 8.44, 12.26, 13.34, 9.44, 9.46, 8.78, 9.08, 9.06, 10.08, 9.200000000000001, 7.58, 14.94, 13.72, 11.98, 8.74, 10.76, 12.58, 9.26, 12.700000000000001, 6.38, 14.38, 5.5200000000000005, 7.640000000000001, 6.7, 9.96, 2.3000000000000003, 10.88, 9.9, 10.52, 7.3, 15.8, 11.06, 6.74, 8.42, 6.26, 8.66, 9.6, 9.540000000000001, 15.42, 12.280000000000001, 11.26, 10.72, 7.88, 8.74, 11.3, 11.16, 11.4, 7.82, 9.700000000000001, 8.1, 7.78, 10.88, 7.34, 5.24, 6.2, 4.28, 9.700000000000001, 8.86, 10.28, 15.08, 9.3, 9.52, 8.4, 3.24, 10.68, 9.78, 13.88, 14.1, 13.92, 15.34, 10.14, 10.700000000000001, 10.46, 10.86, 5.2, 12.82, 9.92, 9.1, 7.32, 18.36, 13.0, 5.6000000000000005, 4.5600000000000005, 3.96, 10.94, 8.94, 13.98, 14.120000000000001, 6.84, 6.92, 8.8, 9.200000000000001, 12.94, 7.0200000000000005, 11.4, 12.620000000000001, 14.84, 11.24, 10.8, 10.46, 8.5, 15.48, 5.26, 12.02, 11.38, 11.32, 8.68, 4.5600000000000005, 9.48, 10.74, 9.74, 7.140000000000001, 11.58, 7.98, 8.76, 13.02, 10.5, 7.36, 8.620000000000001, 5.48, 10.06, 11.700000000000001, 15.34, 11.8, 11.120000000000001, 8.92, 6.66, 14.24, 7.12, 11.66, 11.68, 9.88, 7.5600000000000005, 10.8, 5.92, 13.42, 10.68, 12.24, 8.6, 15.56, 10.28, 10.26, 5.62, 8.08, 7.68, 6.88, 13.58, 11.08, 7.92, 11.540000000000001, 5.62, 11.1, 4.82, 11.72, 8.8, 11.78, 14.84, 6.3, 5.2, 7.18, 9.58, 4.0600000000000005, 10.040000000000001, 10.78, 5.94, 10.84, 10.9, 6.86, 7.68, 11.32, 6.6000000000000005, 2.08, 7.66, 7.46, 8.26, 11.22, 6.96, 6.6000000000000005, 5.84, 13.06, 10.44, 9.46, 5.44, 14.22, 10.700000000000001, 10.44, 12.120000000000001, 6.0600000000000005, 9.38, 15.96, 11.1, 12.3, 9.68, 9.34, 10.9, 11.58, 11.48, 11.94, 14.8, 9.66, 10.1, 11.28, 10.26, 9.82, 16.36, 4.68, 10.16, 11.6, 11.0, 8.68, 14.74, 9.48, 12.14, 10.42, 10.28, 11.82, 9.42, 12.540000000000001, 8.98, 5.0600000000000005, 14.3, 15.1, 11.5, 12.9, 9.74, 6.34, 13.18, 6.3, 8.82, 11.6, 8.540000000000001, 4.14, 9.96, 9.24, 4.5, 10.34, 12.620000000000001, 11.56, 12.4, 12.22, 11.32, 5.14, 15.860000000000001, 10.72, 8.42, 6.76, 8.1, 3.38, 4.32, 6.26, 0.9400000000000001, 13.120000000000001, 13.16, 3.9, 10.9, 12.780000000000001, 12.84, 7.42, 12.4, 10.040000000000001, 13.700000000000001, 12.86, 6.24, 14.1, 4.72, 13.48, 8.82, 6.8, 12.42, 9.98, 5.44, 9.76, 14.84, 14.86, 11.64, 11.700000000000001, 7.7, 7.66, 15.52, 11.98, 4.48, 8.5, 5.14, 11.4, 11.96, 10.06, 11.92, 10.42, 4.62, 9.540000000000001, 13.9, 11.42, 10.700000000000001, 1.16, 8.52, 14.98, 10.14, 6.86, 9.18, 7.74, 8.82, 7.36, 10.66, 9.08, 12.64, 10.08, 5.92, 5.38, 7.22, 10.6, 7.36, 9.28, 11.48, 5.18, 8.96, 9.0, 10.48, 14.06, 12.42, 8.28, 12.16, 4.34, 5.68, 11.68, 8.82, 5.32, 11.82, 7.46, 7.96, 10.120000000000001, 8.96, 10.22, 8.040000000000001, 9.32, 11.32, 11.46, 9.02, 11.98, 12.700000000000001, 14.72, 4.9, 8.06, 8.4, 8.700000000000001, 11.64, 12.58, 10.38, 6.44, 7.22, 14.9, 13.040000000000001, 8.120000000000001, 7.28, 14.02, 11.48, 8.36, 7.72, 10.98, 14.58, 9.1, 14.34, 7.2, 16.46, 10.3, 12.06, 8.82, 11.0, 7.0, 8.52, 13.58, 9.28, 12.76, 2.56, 12.280000000000001, 6.9, 11.38, 11.02, 6.08, 6.24, 6.04, 6.38, 10.0, 14.02, 12.76, 2.64, 3.18, 9.02, 5.64, 11.78, 10.26, 9.14, 8.700000000000001, 12.96, 12.280000000000001, 9.6, 6.54, 9.78, 5.96, 9.66, 11.540000000000001, 10.56, 10.98, 6.98, 10.200000000000001, 8.86, 9.4, 8.3, 9.5, 8.42, 7.24, 7.7, 9.48, 11.68, 13.040000000000001, 9.38, 8.6, 10.32, 8.92, 7.5200000000000005, 6.66, 7.08, 13.88, 9.16, 13.9, 11.26, 7.72, 10.76, 12.08, 7.4, 9.6, 9.040000000000001, 7.78, 16.76, 13.22, 9.92, 16.22, 5.0200000000000005, 9.84, 9.64]\n",
            "[ -3.432, -3.076] : \n",
            "[ -3.076, -2.720] : \n",
            "[ -2.720, -2.364] : \n",
            "[ -2.364, -2.008] : #\n",
            "[ -2.008, -1.652] : ####\n",
            "[ -1.652, -1.296] : ######\n",
            "[ -1.296, -0.940] : ###########\n",
            "[ -0.940, -0.584] : ################\n",
            "[ -0.584, -0.228] : ####################\n",
            "[ -0.228,  0.128] : ################\n",
            "[  0.128,  0.484] : ##################\n",
            "[  0.484,  0.840] : ###############\n",
            "[  0.840,  1.196] : #########\n",
            "[  1.196,  1.552] : #######\n",
            "[  1.552,  1.908] : ###\n",
            "[  1.908,  2.264] : ###\n",
            "[  2.264,  2.620] : \n",
            "[  2.620,  2.976] : \n",
            "[  2.976,  3.332] : \n",
            "[  3.332,  3.688] : \n",
            "g1 mean = -0.03141599999999989\n",
            "g1 variance = 1.0479690029439992\n",
            "[  0.940,  1.834] : \n",
            "[  1.834,  2.728] : \n",
            "[  2.728,  3.622] : #\n",
            "[  3.622,  4.516] : ##\n",
            "[  4.516,  5.410] : #####\n",
            "[  5.410,  6.304] : ######\n",
            "[  6.304,  7.198] : ##########\n",
            "[  7.198,  8.092] : ##############\n",
            "[  8.092,  8.986] : ###################\n",
            "[  8.986,  9.880] : ##################\n",
            "[  9.880, 10.774] : ####################\n",
            "[ 10.774, 11.668] : ##################\n",
            "[ 11.668, 12.562] : ##############\n",
            "[ 12.562, 13.456] : ###########\n",
            "[ 13.456, 14.350] : #######\n",
            "[ 14.350, 15.244] : ####\n",
            "[ 15.244, 16.138] : ##\n",
            "[ 16.138, 17.032] : #\n",
            "[ 17.032, 17.926] : \n",
            "[ 17.926, 18.820] : \n",
            "g2 mean = 9.907799999999993\n",
            "g2 variance = 8.300915960000015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X96qgN8_1iD",
        "colab_type": "text"
      },
      "source": [
        "*Exercise 9:* Combine your `generate_function`, `where`, and `in_range` functions above to create an integrate function. Use your integrate function to show that approximately 68% of Normal distribution is within one variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A51dSStW_1iF",
        "colab_type": "code",
        "outputId": "8071f6c6-8402-44f2-9df9-b67698eaf0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "def integrate(func, x_min, x_max, n_points=1000):\n",
        "  # monte carlo integral\n",
        "  # max f(x) over [x_min, x_max] in steps of (1/1000 or 1/n_points) * the difference\n",
        "  f_max = max([func(x) for x in [x_min + n * (x_max - x_min) / max(1000, n_points) for n in range(max(1000, n_points))]])\n",
        "  # generate n_points random x and y values on a grid x = [x_min, x_max] and y = [0, f_max]\n",
        "  x_rand = [x_min + random.random() * (x_max - x_min) for n in range(n_points)]\n",
        "  y_rand = [random.random() * f_max for n in range(n_points)]\n",
        "  # return height * width * (# of points on grid below the function curve)\n",
        "  #                             # of pts where passing x and y as tuples                0 < y < func(x)\n",
        "  return f_max * (x_max - x_min) * len(where(list(zip(x_rand, y_rand)), lambda xy: in_range(0, func(xy[0]))(xy[1]))) / n_points\n",
        "\n",
        "\n",
        "def integrate_properly(func, x_min, x_max, n_points=1000):\n",
        "  # proper integral\n",
        "  i = x_min\n",
        "  integral = 0\n",
        "  dx = (x_max - x_min) / n_points\n",
        "  while i < x_max:\n",
        "    integral += func(i) * dx\n",
        "    i += dx\n",
        "  return integral\n",
        "\n",
        "\n",
        "print(\"  data: {:4.3f}\".format(integrate(lambda x: -((x - 10) ** 2) + 100, 0, 20, 10000)))\n",
        "print(\"theory: {:4.3f}\".format(integrate_properly(lambda x: -((x - 10) ** 2) + 100, 0, 20, 10000)))\n",
        "print(\"   d/t: {:3.1f}%\".format(100*integrate(lambda x: -((x - 10) ** 2) + 100, 0, 20, 10000)/integrate_properly(lambda x: -((x - 10) ** 2) + 100, 0, 20, 10000)))\n",
        "print(\"  data: {:1.3f}\".format(integrate(g2, 7, 13, 10000)/integrate(g2, 0, 20, 10000)))\n",
        "print(\"theory: {:1.3f}\".format(integrate_properly(g2, 7, 13, 10000)/integrate_properly(g2, 0, 20, 10000)))\n",
        "print(\"   d/t: {:3.1f}%\".format(100*(integrate(g2, 7, 13, 10000)/integrate(g2, 0, 20, 10000))/(integrate_properly(g2, 7, 13, 10000)/integrate_properly(g2, 0, 20, 10000))))"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  data: 1330.600\n",
            "theory: 1333.333\n",
            "   d/t: 99.8%\n",
            "  data: 0.680\n",
            "theory: 0.683\n",
            "   d/t: 99.5%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d87Vi_Zj_1iL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}